<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<title>CombineHarvester: Reproducing Run 1 H-&gt;tautau results</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 70px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">CombineHarvester
   </div>
  </td>
   <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.svg"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('introrun1_h_t_t.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Reproducing Run 1 H-&gt;tautau results </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_docs_ReproduceRun1HTTDatacards"></a></p>
<p>Using all of the techniques described previously, both in terms of datacard production and usage of the RooMorphingPdf object for signal processes, code to reproduce many of the Run 1 H-&gt;tautau results is included in the package. For some analyses, development was first performed for the datacard production without morphing applied, and fully validated, before moving to using morphing for the signal process. Note that in the non-morphing version many of the analyses have an equivalent python version. Once the usage of RooMorphingPdf for signal was validated in several use cases some additional analyses were added making use of this method only. This section describes how to find the code for each of the legacy analyses and details any specifics beyond the previous examples. More detail on the validation which was made can be found in the analysis note AN-15-235. Note that to run all of the examples below, the shape files exist in /auxiliaries and are linked to the script correctly. For more information on running the statistical results with the produced datacards, see later sections.</p>
<h1><a class="anchor" id="run1HTTsystematics"></a>
Systematics for legacy H-&gt;tautau results</h1>
<p><b>Files</b> <a class="el" href="_htt_systematics_8h.html">CombineTools/interface/HttSystematics.h</a>, CombineTools/python/systematics</p>
<p>For analyses with a large number of systematic uncertainties, it is neater to detail these in a separate file from the main datacard production code. Files for the different analyses can be found at the paths above, either in c++ or python.</p>
<h1><a class="anchor" id="run1HTTSM"></a>
Legacy SM H-&gt;tautau results</h1>
<p><b>Files</b> : <a class="el" href="_s_m_legacy_example_8cpp.html">CombineTools/bin/SMLegacyExample.cpp</a>, CombineTools/scripts/SMLegacyExample.py</p>
<p><b>Files</b> : CombinePdfs/bin/SMLegacyMorphing.cpp</p>
<p>The datacards for the legacy SM H-&gt;tautau results can be produced using the files listed above, available in both c++ and python. The code currently includes all the main tautau channels: ee, mm, mt, et, em and tt, and not the VH channels. The datacards are up to date with those used in the most recent CMS-ATLAS combination.</p>
<p>The code itself makes use of similar functions as to those already described for Example1 and Example2. A few new features are used as well:</p>
<p>1) Scaling signals by a cross-section times branching ratio factor</p>
<p>Generally for the SM analysis, limits are set on best fit signal strength mu with reference to the SM prediction for cross section times branching ratio. Thus it makes sense to scale the signal according to this value when filling the datacard. This can be done via code like:</p>
<div class="fragment"><div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;&gt;&gt; Scaling signal process rates...\n&quot;</span>;</div>
<div class="line">  map&lt;string, TGraph&gt; xs;</div>
<div class="line">  <span class="comment">// Get the table of H-&gt;tau tau BRs vs mass</span></div>
<div class="line">  xs[<span class="stringliteral">&quot;htt&quot;</span>] = <a class="code" href="namespacech.html#a847fd9dc77ba21e35a6b531e1d26902a">ch::TGraphFromTable</a>(input_dir+<span class="stringliteral">&quot;/xsecs_brs/htt_YR3.txt&quot;</span>, <span class="stringliteral">&quot;mH&quot;</span>, <span class="stringliteral">&quot;br&quot;</span>);</div>
<div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">string</span> <span class="keyword">const</span>&amp; e : {<span class="stringliteral">&quot;7TeV&quot;</span>, <span class="stringliteral">&quot;8TeV&quot;</span>}) {</div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">string</span> <span class="keyword">const</span>&amp; p : sig_procs) {</div>
<div class="line">      <span class="comment">// Get the table of xsecs vs mass for process &quot;p&quot; and era &quot;e&quot;:</span></div>
<div class="line">      xs[p+<span class="stringliteral">&quot;_&quot;</span>+e] = <a class="code" href="namespacech.html#a847fd9dc77ba21e35a6b531e1d26902a">ch::TGraphFromTable</a>(input_dir+<span class="stringliteral">&quot;/xsecs_brs/&quot;</span>+p+<span class="stringliteral">&quot;_&quot;</span>+e+<span class="stringliteral">&quot;_YR3.txt&quot;</span>, <span class="stringliteral">&quot;mH&quot;</span>, <span class="stringliteral">&quot;xsec&quot;</span>);</div>
<div class="line">      cout &lt;&lt; <span class="stringliteral">&quot;&gt;&gt;&gt;&gt; Scaling for process &quot;</span> &lt;&lt; p &lt;&lt; <span class="stringliteral">&quot; and era &quot;</span> &lt;&lt; e &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;</div>
<div class="line">      cb.cp().process({p}).era({e}).ForEachProc([&amp;](<a class="code" href="classch_1_1_process.html">ch::Process</a> *proc) {</div>
<div class="line">        <span class="keywordtype">double</span> m = boost::lexical_cast&lt;double&gt;(proc-&gt;<a class="code" href="classch_1_1_object.html#ae2f9e80af391e105a6b6bc27107e3c9e">mass</a>());</div>
<div class="line">        proc-&gt;<a class="code" href="classch_1_1_process.html#a178a4692175af3cb3f9699f424a03b30">set_rate</a>(proc-&gt;<a class="code" href="classch_1_1_process.html#a4683fb53999bbc1cbefb5637a4843e55">rate</a>() * xs[p+<span class="stringliteral">&quot;_&quot;</span>+e].Eval(m) * xs[<span class="stringliteral">&quot;htt&quot;</span>].Eval(m));</div>
<div class="line">      });</div>
<div class="line">    }</div>
<div class="line">  }</div>
<div class="ttc" id="aclassch_1_1_object_html_ae2f9e80af391e105a6b6bc27107e3c9e"><div class="ttname"><a href="classch_1_1_object.html#ae2f9e80af391e105a6b6bc27107e3c9e">ch::Object::mass</a></div><div class="ttdeci">virtual std::string const  &amp; mass() const</div><div class="ttdef"><b>Definition:</b> <a href="_object_8h_source.html#l00038">Object.h:38</a></div></div>
<div class="ttc" id="aclassch_1_1_process_html"><div class="ttname"><a href="classch_1_1_process.html">ch::Process</a></div><div class="ttdef"><b>Definition:</b> <a href="_process_8h_source.html#l00015">Process.h:15</a></div></div>
<div class="ttc" id="aclassch_1_1_process_html_a178a4692175af3cb3f9699f424a03b30"><div class="ttname"><a href="classch_1_1_process.html#a178a4692175af3cb3f9699f424a03b30">ch::Process::set_rate</a></div><div class="ttdeci">void set_rate(double const &amp;rate)</div><div class="ttdef"><b>Definition:</b> <a href="_process_8h_source.html#l00024">Process.h:24</a></div></div>
<div class="ttc" id="aclassch_1_1_process_html_a4683fb53999bbc1cbefb5637a4843e55"><div class="ttname"><a href="classch_1_1_process.html#a4683fb53999bbc1cbefb5637a4843e55">ch::Process::rate</a></div><div class="ttdeci">double rate() const</div><div class="ttdef"><b>Definition:</b> <a href="_process_8h_source.html#l00025">Process.h:25</a></div></div>
<div class="ttc" id="anamespacech_html_a847fd9dc77ba21e35a6b531e1d26902a"><div class="ttname"><a href="namespacech.html#a847fd9dc77ba21e35a6b531e1d26902a">ch::TGraphFromTable</a></div><div class="ttdeci">TGraph TGraphFromTable(std::string filename, std::string const &amp;x_column, std::string const &amp;y_column)</div><div class="ttdef"><b>Definition:</b> <a href="_utilities_8cc_source.html#l00121">Utilities.cc:121</a></div></div>
</div><!-- fragment --><p> This reads the values for cross section times branching ratio from a text file and then uses them to scale each of the signal processes by the appropriate value. <br  />
</p>
<p>2) Merging bin by bin uncertainties</p>
<p>The addition of bin by bin uncertainties was illustrated in Example2. The SM H-&gt;tautau code uses an additional option in the BinByBinFactory which allows the user to merge uncertainties from different background processes in a given bin. This can be useful when an analysis has a large number of bins and/or processes contributing, such that adding a separate nuisance for each case would be costly in computing time for the limit calculations. The code starts in the same way as in Example2, by setting up the BinByBinFactory as follows:</p>
<div class="fragment"><div class="line">  <span class="keyword">auto</span> bbb = <a class="code" href="classch_1_1_bin_by_bin_factory.html">ch::BinByBinFactory</a>()</div>
<div class="line">      .<a class="code" href="classch_1_1_bin_by_bin_factory.html#a022063406869d59a03e7aef47ce53e34">SetAddThreshold</a>(0.1)</div>
<div class="line">      .<a class="code" href="classch_1_1_bin_by_bin_factory.html#aa983d4e391adbf5a7af40458a3ffc062">SetMergeThreshold</a>(0.5)</div>
<div class="line">      .<a class="code" href="classch_1_1_bin_by_bin_factory.html#a05d997b69c619df3c2f7d20e4e7106b7">SetFixNorm</a>(<span class="keyword">true</span>);</div>
<div class="ttc" id="aclassch_1_1_bin_by_bin_factory_html"><div class="ttname"><a href="classch_1_1_bin_by_bin_factory.html">ch::BinByBinFactory</a></div><div class="ttdoc">Merges bin uncertainties and creates bin-by-bin statistical uncertainties.</div><div class="ttdef"><b>Definition:</b> <a href="_bin_by_bin_8h_source.html#l00021">BinByBin.h:21</a></div></div>
<div class="ttc" id="aclassch_1_1_bin_by_bin_factory_html_a022063406869d59a03e7aef47ce53e34"><div class="ttname"><a href="classch_1_1_bin_by_bin_factory.html#a022063406869d59a03e7aef47ce53e34">ch::BinByBinFactory::SetAddThreshold</a></div><div class="ttdeci">BinByBinFactory &amp; SetAddThreshold(double val)</div><div class="ttdoc">Set the fractional bin error threshold for bin-by-bin creation and for participation in the merging a...</div><div class="ttdef"><b>Definition:</b> <a href="_bin_by_bin_8h_source.html#l00099">BinByBin.h:99</a></div></div>
<div class="ttc" id="aclassch_1_1_bin_by_bin_factory_html_a05d997b69c619df3c2f7d20e4e7106b7"><div class="ttname"><a href="classch_1_1_bin_by_bin_factory.html#a05d997b69c619df3c2f7d20e4e7106b7">ch::BinByBinFactory::SetFixNorm</a></div><div class="ttdeci">BinByBinFactory &amp; SetFixNorm(bool fix)</div><div class="ttdoc">Whether or not the bin-by-bin systematics are allowed to vary the process normalisation.</div><div class="ttdef"><b>Definition:</b> <a href="_bin_by_bin_8h_source.html#l00124">BinByBin.h:124</a></div></div>
<div class="ttc" id="aclassch_1_1_bin_by_bin_factory_html_aa983d4e391adbf5a7af40458a3ffc062"><div class="ttname"><a href="classch_1_1_bin_by_bin_factory.html#aa983d4e391adbf5a7af40458a3ffc062">ch::BinByBinFactory::SetMergeThreshold</a></div><div class="ttdeci">BinByBinFactory &amp; SetMergeThreshold(double val)</div><div class="ttdoc">The threshold for the merging algorithm.</div><div class="ttdef"><b>Definition:</b> <a href="_bin_by_bin_8h_source.html#l00107">BinByBin.h:107</a></div></div>
</div><!-- fragment --><p> In this example the merge threshold is set to 0.5. This controls the proportion of the total error that is allowed to be merged. The add threshold controls the value below which the stat uncertainty should be for the bin by bin uncertainty to be added. The uncertainties for different processes can then be added and merged simultaneously using calls like:</p>
<div class="fragment"><div class="line">  bbb.MergeAndAdd(cb_et.cp().era({<span class="stringliteral">&quot;8TeV&quot;</span>}).bin_id({6}).process({<span class="stringliteral">&quot;ZL&quot;</span>, <span class="stringliteral">&quot;ZJ&quot;</span>, <span class="stringliteral">&quot;W&quot;</span>}), cb);</div>
</div><!-- fragment --><p> The filters for eta, bin id and channel can be used in this way to add the specific requirements for each channel and category, of which there were many for the legacy SM analysis.</p>
<p>3) Pruning uncertainties</p>
<p>Alongside merging of bin by bin uncertainties, another trick is employed in the SM analysis to help reduce the computing time for the limits. The method is to first run a maximum likelihood fit in each of the channels separately, using the full uncertainty model, and then use the information on the impacts of the uncertainties to judge which ones have a negligible effect on the fit result. These are then removed from the uncertainty model for the full combined fit. The procedure is to read in a text file which includes the list of uncertainties to be dropped (this was created at the time using the old statistical framework, but could easily be created again if required). The systematics added to the CH instance are then filtered using this list, with code as follows:</p>
<div class="fragment"><div class="line">  VString droplist = <a class="code" href="namespacech.html#a23a4079d5c68e21d9697570255e08224">ch::ParseFileLines</a>(</div>
<div class="line">    aux_pruning + <span class="stringliteral">&quot;uncertainty-pruning-drop-131128-sm.txt&quot;</span>);</div>
<div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;&gt;&gt; Droplist contains &quot;</span> &lt;&lt; droplist.size() &lt;&lt; <span class="stringliteral">&quot; entries\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">  set&lt;string&gt; to_drop;</div>
<div class="line">  <span class="keywordflow">for</span> (<span class="keyword">auto</span> x : droplist) to_drop.insert(x);</div>
<div class="line"> </div>
<div class="line">  <span class="keyword">auto</span> pre_drop = cb.syst_name_set();</div>
<div class="line">  cb.syst_name(droplist, <span class="keyword">false</span>);</div>
<div class="line">  <span class="keyword">auto</span> post_drop = cb.syst_name_set();</div>
<div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;&gt;&gt; Systematics dropped: &quot;</span> &lt;&lt; pre_drop.size() - post_drop.size()</div>
<div class="line">            &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;</div>
<div class="ttc" id="anamespacech_html_a23a4079d5c68e21d9697570255e08224"><div class="ttname"><a href="namespacech.html#a23a4079d5c68e21d9697570255e08224">ch::ParseFileLines</a></div><div class="ttdeci">std::vector&lt; std::string &gt; ParseFileLines(std::string const &amp;file_name)</div><div class="ttdef"><b>Definition:</b> <a href="_utilities_8cc_source.html#l00224">Utilities.cc:224</a></div></div>
</div><!-- fragment --><p> The validation of the produced SM cards as compared to the official cards can be found in the Analysis Note.</p>
<h1><a class="anchor" id="run1HTTHhhAZh"></a>
Run 1 H-&gt;hh-&gt;bbtautau and A-&gt;Zh-&gt;lltautau results</h1>
<p><b>Files</b> Run1BSMComb/bin/AZh.cpp, Run1BSMComb/bin/Hhh.cpp, CombineTools/scripts/HhhExample.py</p>
<p><b>Files</b> Run1BSMComb/bin/MorphingAZh.cpp, Run1BSMComb/bin/MorphingHhh.cpp</p>
<p>The above scripts illustrate the datacard production for the H-&gt;hh and A-&gt;Zh analyses of HIG-14-034. The cards are very similar to those shown previously. The H-&gt;hh analysis makes use of the bin by bin merging functions exactly as described for the SM analysis. The A-&gt;Zh analysis makes use of one feature described for the SM cards- the ability to multiply signal by a constant factor. In this case the factor is 1000 to put the signal into femptobarns instead of picobarns. <br  />
</p>
<p>The validation of the produced cards as compared to the official cards can be found in the Analysis note.</p>
<h1><a class="anchor" id="run1HTTMSSM"></a>
MSSM update H-&gt;tautau results</h1>
<p><b>File</b> Run1BSMComb/bin/MorphingMSSMUpdate.cpp</p>
<p>The fit model for the MSSM update analysis is similarly complicated to the SM legacy analysis. There are a couple of unique features which are illustrated below:</p>
<p>1) Possibility to setup 3 Higgs bosons</p>
<p>In the MSSM there are three neutral Higgs bosons, and to set a limit on a particular MSSM model the signal model contains all three for the correct mass and ratios of cross section times branching ratios. For the model dependent limits therefore we need to have 6 separate signal processes in the datacards, one for each of the three neutral Higgs bosons, multiplied by two for the two different signal production mechanisms. This is done by mapping what exists in the shape files (two signal production processes generically named ggH and bbH, which can stand for any one of the three Higgs bosons) to the signal processes we want, using the following:</p>
<div class="fragment"></div><!-- fragment --><p> When declaring the processes to be added to the CH instance, the full set of signal processes is included:</p>
<div class="fragment"></div><!-- fragment --><p> Whereas when reading in the information from the shape file the usual names are used the individual ggH and bbH templates are used to fill the processes for all 3 Higgs bosons:</p>
<div class="fragment"></div><!-- fragment --><p> When running model dependent limits, the 6 signal processes are used and manipulated in the required way to build a signal template for a given mA-tanb point. When running model independent limits, the datacards are simply setup with only one neutral Higgs boson, as appropriate for a single resonance search.</p>
<p>2) Tail fit uncertainties</p>
<p>During Run 1 for the MSSM analysis an analytic fit was performed to the high mass tail of the mass distribution for some of the backgrounds and associated systematics were included, in order to reduce problems with low statistics in the tails. For the initial implementation of the Run 1 cards, these tail fits are added 'by hand', i.e. directly included in the input shape file rather than the fits rerun. The systematics are then lifted from the shape file directly as shape uncertainties in the format:</p>
<div class="fragment"><div class="line">  src.cp().process({<span class="stringliteral">&quot;W&quot;</span>})</div>
<div class="line">      .AddSyst(cb, <span class="stringliteral">&quot;CMS_shift1_muTau_nobtag_low_$ERA_W_fine_binning&quot;</span>, <span class="stringliteral">&quot;shape&quot;</span>, SystMap&lt;channel, bin_id&gt;::init({<span class="stringliteral">&quot;mt&quot;</span>}, {10}, 1.000));</div>
</div><!-- fragment --><p> The validation of the MSSM update analysis has been performed in terms of the model independent and model dependent limits and is detailed in the Analysis note. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.6-->
<!-- start footer part -->
</body>
</html>
